{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3.5 Final Baseline (train_gpt_original.py, 1 seed) vs Stage 3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /workspace/ese-3060-project/.venv/bin/activate\n",
    "python -m ipykernel install --user --name ese3060-venv --display-name \"ese3060 venv\"\n",
    "echo \"Kernel installed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, subprocess, json, glob, re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%cd /workspace/ese-3060-project\n",
    "\n",
    "# Detect project root: prefer PROJ_ROOT env, else repo root (parent if running from notebooks/)\n",
    "cwd = Path.cwd().expanduser().resolve()\n",
    "default_root = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "PROJ_ROOT = Path(os.environ.get('PROJ_ROOT', default_root)).expanduser().resolve()\n",
    "SCRIPT_PATH = PROJ_ROOT / 'train_gpt_original.py'\n",
    "RESULTS_ALL = PROJ_ROOT / 'experiments' / 'results.csv'\n",
    "RESULTS_STAGE3 = PROJ_ROOT / 'experiments' / 'results_stage3.csv'\n",
    "RESULTS_STAGE3_ALT = PROJ_ROOT / 'experiments' / 'results_stage_3.csv'\n",
    "BASELINE_OUT = PROJ_ROOT / 'experiments' / 'baseline.csv'\n",
    "LOG_DIR = PROJ_ROOT / 'logs'\n",
    "\n",
    "print('Project root:', PROJ_ROOT)\n",
    "print('Using script:', SCRIPT_PATH)\n",
    "print('Results files checked:', RESULTS_STAGE3, RESULTS_STAGE3_ALT, RESULTS_ALL)\n",
    "print('Logs:', LOG_DIR)\n",
    "print('Baseline export:', BASELINE_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime knobs (one seed baseline)\n",
    "NPROC = None                # auto-detect GPU count if None\n",
    "SEED = 1337                # train_gpt_original.py reads SEED env\n",
    "VAL_EVERY = 125            # train_gpt_original.py reads VAL_EVERY env\n",
    "TORCHRUN = \"torchrun\"\n",
    "LAUNCH = False              # set True to run\n",
    "\n",
    "# train_gpt_original.py uses built-in defaults for lr/iters/warmdown; not adjustable here\n",
    "if NPROC is None:\n",
    "    try:\n",
    "        gpu_count = int(subprocess.check_output(\"nvidia-smi --list-gpus | wc -l\", shell=True).decode().strip())\n",
    "    except Exception:\n",
    "        gpu_count = 0\n",
    "    NPROC = max(gpu_count, 1)\n",
    "\n",
    "assert SCRIPT_PATH.exists(), f\"Missing train script: {SCRIPT_PATH}\"\n",
    "\n",
    "def run_baseline(seed):\n",
    "    env = os.environ.copy()\n",
    "    env.update({\n",
    "        \"SEED\": str(seed),\n",
    "        \"VAL_EVERY\": str(VAL_EVERY),\n",
    "    })\n",
    "    cmd = [TORCHRUN, \"--standalone\", f\"--nproc_per_node={NPROC}\", str(SCRIPT_PATH)]\n",
    "    print(f\"\\n>>> Launching baseline (train_gpt_original) seed={seed} nproc={NPROC}\")\n",
    "    if not LAUNCH:\n",
    "        return 0\n",
    "    proc = subprocess.run(cmd, env=env)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f\"Run failed: baseline seed {seed} rc={proc.returncode}\")\n",
    "\n",
    "run_baseline(SEED)\n",
    "print(\"Done (LAUNCH=\" + str(LAUNCH) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse latest baseline log and save to baseline.csv\n",
    "VAL_RE = re.compile(r\"step:(\\d+)/(\\d+) val_loss:([0-9.]+) train_time:(\\d+)ms step_avg:([0-9.]+)ms\")\n",
    "\n",
    "def parse_latest_log(log_dir: Path):\n",
    "    if not log_dir.exists():\n",
    "        return None, None\n",
    "    txts = sorted(log_dir.glob('*.txt'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    if not txts:\n",
    "        return None, None\n",
    "    path = txts[0]\n",
    "    rows = []\n",
    "    for line in open(path):\n",
    "        m = VAL_RE.search(line)\n",
    "        if m:\n",
    "            step = int(m.group(1)); total = int(m.group(2))\n",
    "            vloss = float(m.group(3)); t_ms = int(m.group(4)); step_avg = float(m.group(5))\n",
    "            rows.append((step, total, vloss, t_ms, step_avg))\n",
    "    if not rows:\n",
    "        return path.stem, None\n",
    "    final = rows[-1]\n",
    "    best = min(rows, key=lambda r: r[2])\n",
    "    data = {\n",
    "        'run_id': path.stem,\n",
    "        'seed': SEED,\n",
    "        'learning_rate': LR,\n",
    "        'num_iterations': final[1],\n",
    "        'warmdown_iters': WARMDOWN_ITERS,\n",
    "        'final_val_loss': final[2],\n",
    "        'best_val_loss': best[2],\n",
    "        'train_time_ms': final[3],\n",
    "        'ms_per_step': final[4],\n",
    "        'attn_gate': 'none',\n",
    "    }\n",
    "    return path.stem, pd.DataFrame([data])\n",
    "\n",
    "log_id, baseline_df = parse_latest_log(LOG_DIR)\n",
    "if baseline_df is not None:\n",
    "    BASELINE_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    baseline_df.to_csv(BASELINE_OUT, index=False)\n",
    "    display(baseline_df)\n",
    "    print(f\"Saved baseline run ({log_id}) to {BASELINE_OUT}\")\n",
    "else:\n",
    "    print('No baseline log parsed; ensure run was launched.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stage 3 results for comparison\n",
    "if RESULTS_STAGE3.exists():\n",
    "    stage3 = pd.read_csv(RESULTS_STAGE3)\n",
    "elif RESULTS_STAGE3_ALT.exists():\n",
    "    stage3 = pd.read_csv(RESULTS_STAGE3_ALT)\n",
    "elif RESULTS_ALL.exists():\n",
    "    stage3 = pd.read_csv(RESULTS_ALL)\n",
    "else:\n",
    "    stage3 = pd.DataFrame()\n",
    "\n",
    "if not stage3.empty:\n",
    "    # Optional filter for full-run params if needed\n",
    "    pass\n",
    "stage3.head() if not stage3.empty else stage3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline (parsed) vs stage3 elementwise/baseline rows\n",
    "if baseline_df is not None and not baseline_df.empty:\n",
    "    # align columns of interest\n",
    "    cols = ['attn_gate','learning_rate','best_val_loss','final_val_loss','ms_per_step','train_time_ms','run_id','seed']\n",
    "    comp_list = [baseline_df[cols]]\n",
    "    if not stage3.empty:\n",
    "        stage_subset = stage3.copy()\n",
    "        missing = [c for c in cols if c not in stage_subset.columns]\n",
    "        for c in missing:\n",
    "            stage_subset[c] = pd.NA\n",
    "        comp_list.append(stage_subset[cols])\n",
    "    comp = pd.concat(comp_list, ignore_index=True)\n",
    "    display(comp)\n",
    "    # Simple bar for best_val_loss\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.bar(comp['attn_gate'], comp['best_val_loss'])\n",
    "    ax.set_ylabel('best_val_loss')\n",
    "    ax.set_title('Baseline (train_gpt_original) vs stage3 results')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print('No baseline_df to compare.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988803a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute theoretical loss at baseline wall-clock time using linear interpolation\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Determine baseline wall-clock time from baseline_df if present\n",
    "baseline_time_ms = None\n",
    "if baseline_df is not None and not baseline_df.empty:\n",
    "    baseline_time_ms = float(baseline_df.iloc[0]['train_time_ms'])\n",
    "else:\n",
    "    print('Baseline timing not found; cannot compute theoretical losses.')\n",
    "\n",
    "if baseline_time_ms is not None and not curves.empty:\n",
    "    def interpolate_loss(sub, target_ms):\n",
    "        sub = sub.sort_values('train_time_ms')\n",
    "        t = sub['train_time_ms'].values\n",
    "        v = sub['val_loss'].values\n",
    "        if target_ms <= t.min():\n",
    "            return v[0]\n",
    "        if target_ms >= t.max():\n",
    "            return v[-1]\n",
    "        return np.interp(target_ms, t, v)\n",
    "\n",
    "    rows = []\n",
    "    for gate, sub in curves.groupby('attn_gate'):\n",
    "        # average across runs at the baseline time by interpolating each run then averaging\n",
    "        vals = []\n",
    "        for rid, rsub in sub.groupby('run_id'):\n",
    "            vals.append(interpolate_loss(rsub, baseline_time_ms))\n",
    "        if vals:\n",
    "            rows.append({'attn_gate': gate, 'theoretical_val_loss_at_baseline_time': float(np.mean(vals))})\n",
    "    final_table = pd.DataFrame(rows)\n",
    "    display(final_table)\n",
    "else:\n",
    "    print('No curves or baseline time; cannot compute theoretical losses.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ese3060 venv",
   "language": "python",
   "name": "ese3060-venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
