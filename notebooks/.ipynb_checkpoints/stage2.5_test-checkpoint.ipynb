{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1794848a",
   "metadata": {},
   "source": [
    "# Stage 2.5: Baseline vs Elementwise (1500 iters, wd=1450, lr=0.00468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff3946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec ese3060-venv in /root/.local/share/jupyter/kernels/ese3060-venv\n",
      "Kernel installed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /workspace/ese-3060-project/.venv/bin/activate\n",
    "python -m ipykernel install --user --name ese3060-venv --display-name \"ese3060 venv\"\n",
    "echo \"Kernel installed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1888fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ese-3060-project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/workspace/ese-3060-project', '/workspace/ese-3060-project/train_gpt.py')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, subprocess, json, glob, re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%cd /workspace/ese-3060-project\n",
    "\n",
    "PROJECT_ROOT = os.environ.get('PROJ_ROOT', '/workspace/ese-3060-project')\n",
    "SCRIPT_PATH = os.path.join(PROJECT_ROOT, 'train_gpt.py')\n",
    "RESULTS_ALL = os.path.join(PROJECT_ROOT, 'experiments', 'results.csv')\n",
    "RESULTS = os.path.join(PROJECT_ROOT, 'experiments', 'results_stage2_5.csv')\n",
    "LOG_DIR = os.path.join(PROJECT_ROOT, 'logs')\n",
    "SPLITTER = os.path.join(PROJECT_ROOT, 'scripts', 'split_results.py')\n",
    "PROJECT_ROOT, SCRIPT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ebc1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Launching baseline seed=1337 lr=0.00468 nproc=1\n",
      "using device: cuda:0\n",
      "Training DataLoader: total number of tokens: 900000000 across 9 files\n",
      "Validation DataLoader: total number of tokens: 100000000 across 1 files\n",
      "step:0/1500 val_loss:16.0297 train_time:229ms step_avg:nanms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1208 03:05:11.544000 862 torch/distributed/elastic/agent/server/api.py:723] Received 2 death signal, shutting down workers\n",
      "W1208 03:05:11.545000 862 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 929 closing signal SIGINT\n",
      "[rank0]:[W1208 03:05:12.751736035 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?\n",
      "Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d6a8cd (0x742158ff08cd in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b47a (0x742158ff147a in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x742158fec19e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:12.754825327 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?\n",
      "[rank0]:[W1208 03:05:13.754996394 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:13.757553045 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cfg_name, cfg_env \u001b[38;5;129;01min\u001b[39;00m CONFIGS.items():\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m SEEDS:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m         \u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m LAUNCH:\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# after runs, refresh splits\u001b[39;00m\n\u001b[32m     53\u001b[39m     subprocess.run([\u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m, SPLITTER, \u001b[33m\"\u001b[39m\u001b[33m--stage1-iters\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1500\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m--stage2-iters\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m800\u001b[39m\u001b[33m\"\u001b[39m], check=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mrun_job\u001b[39m\u001b[34m(name, cfg, seed)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LAUNCH:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m proc = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m proc.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproc.returncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:1201\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1199\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1200\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:2053\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2053\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2055\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2056\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:2011\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2009\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2010\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2011\u001b[39m     (pid, sts) = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2012\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2013\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2014\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2015\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2016\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W1208 03:05:14.757721949 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:14.760240843 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:15.760428745 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:15.763043845 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:16.763246599 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:16.766264784 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:17.766501961 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:17.769482078 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:18.769750652 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:18.772726032 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:19.772985662 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:19.775945990 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:20.776197918 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:20.778807109 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:21.779072057 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:21.781587427 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:22.781837031 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:22.784392891 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:23.784640263 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:23.787184134 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:24.787393390 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:24.789893636 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:25.790142019 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:25.792681585 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:26.792935396 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:26.795492388 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:27.795703444 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:27.798226977 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:28.798472385 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:28.801027655 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/workspace/ese-3060-project/train_gpt.py\", line 609, in <module>\n",
      "[rank0]:     loss.backward()\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 647, in backward\n",
      "[rank0]:     torch.autograd.backward(\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "[rank0]:     _engine_run_backward(\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]: KeyboardInterrupt\n",
      "[rank0]:[W1208 03:05:29.801275226 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:29.803800821 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n",
      "[rank0]:[W1208 03:05:30.803989484 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=19, addr=[b0ff8cb6bf81]:38026, remote=[b0ff8cb6bf81]:40703): Broken pipe\n",
      "Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x74221ad7eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x5d694d1 (0x742158fef4d1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x5d69d62 (0x742158fefd62 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: <unknown function> + 0x5d6b86e (0x742158ff186e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x742158fec18e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7421184d1b18 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xecdb4 (0x74221bd5bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #7: <unknown function> + 0x9caa4 (0x74221e2e3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #8: __clone + 0x44 (0x74221e370a64 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[W1208 03:05:30.806477242 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Runtime knobs\n",
    "NPROC = None                # auto-detect if None\n",
    "LR = 0.00468\n",
    "SEEDS = [1337, 2337]        # two runs per config\n",
    "NUM_ITER = 1500\n",
    "WARMUP_ITERS = 0\n",
    "WARMDOWN_ITERS = 1450\n",
    "VAL_EVERY = 125\n",
    "CONFIGS = {\n",
    "    \"baseline\":    {\"ATTNGATE\": \"none\",        \"GATEPOS\": \"sdpa\", \"GATEACT\": \"sigmoid\"},\n",
    "    \"elementwise\": {\"ATTNGATE\": \"elementwise\", \"GATEPOS\": \"sdpa\", \"GATEACT\": \"sigmoid\"},\n",
    "}\n",
    "TORCHRUN = \"torchrun\"\n",
    "LAUNCH = True             # set True to actually run\n",
    "\n",
    "# torchrun helpers\n",
    "if NPROC is None:\n",
    "    try:\n",
    "        gpu_count = int(subprocess.check_output(\"nvidia-smi --list-gpus | wc -l\", shell=True).decode().strip())\n",
    "    except Exception:\n",
    "        gpu_count = 0\n",
    "    NPROC = max(gpu_count, 1)\n",
    "\n",
    "assert os.path.exists(SCRIPT_PATH), f\"Missing train script: {SCRIPT_PATH}\"\n",
    "\n",
    "def run_job(name, cfg, seed):\n",
    "    env = os.environ.copy()\n",
    "    env.update({\n",
    "        \"ATTNGATE\": cfg[\"ATTNGATE\"],\n",
    "        \"GATEPOS\": cfg[\"GATEPOS\"],\n",
    "        \"GATEACT\": cfg[\"GATEACT\"],\n",
    "        \"LR\": str(LR),\n",
    "        \"SEED\": str(seed),\n",
    "        \"NUM_ITERATIONS\": str(NUM_ITER),\n",
    "        \"WARMUP_ITERS\": str(WARMUP_ITERS),\n",
    "        \"WARMDOWN_ITERS\": str(WARMDOWN_ITERS),\n",
    "        \"VAL_EVERY\": str(VAL_EVERY),\n",
    "    })\n",
    "    cmd = [TORCHRUN, \"--standalone\", f\"--nproc_per_node={NPROC}\", SCRIPT_PATH]\n",
    "    print(f\"\\n>>> Launching {name} seed={seed} lr={LR:.5f} nproc={NPROC}\")\n",
    "    if not LAUNCH:\n",
    "        return 0\n",
    "    proc = subprocess.run(cmd, env=env)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f\"Run failed: {name} seed {seed} rc={proc.returncode}\")\n",
    "\n",
    "for cfg_name, cfg_env in CONFIGS.items():\n",
    "    for seed in SEEDS:\n",
    "        run_job(cfg_name, cfg_env, seed)\n",
    "\n",
    "if LAUNCH:\n",
    "    # after runs, refresh splits\n",
    "    subprocess.run([\"python\", SPLITTER, \"--stage1-iters\", \"1500\", \"--stage2-iters\", \"800\"], check=False)\n",
    "\n",
    "print(\"Done (LAUNCH=\" + str(LAUNCH) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0ac5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load results (prefer stage2_5 split if present)\n",
    "if os.path.exists(RESULTS):\n",
    "    df = pd.read_csv(RESULTS)\n",
    "elif os.path.exists(RESULTS_ALL):\n",
    "    df = pd.read_csv(RESULTS_ALL)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "df.head() if not df.empty else df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a77751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grouping\n",
    "stage = df.copy()\n",
    "if not stage.empty:\n",
    "    agg = stage.groupby([\"attn_gate\", \"learning_rate\"]).agg(\n",
    "        runs=(\"run_id\", \"count\"),\n",
    "        mean_best_val=(\"best_val_loss\", \"mean\"),\n",
    "        std_best_val=(\"best_val_loss\", \"std\"),\n",
    "        mean_ms_step=(\"ms_per_step\", \"mean\"),\n",
    "    ).reset_index()\n",
    "    display(agg)\n",
    "    if not agg.empty:\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        for gate, sub in agg.groupby('attn_gate'):\n",
    "            ax.errorbar(sub['learning_rate'], sub['mean_best_val'], yerr=sub['std_best_val'], marker='o', capsize=4, label=gate)\n",
    "        ax.set_xlabel('learning_rate')\n",
    "        ax.set_ylabel('best_val_loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No stage 2.5 data yet; run jobs first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs and plot curves\n",
    "VAL_RE = re.compile(r\"step:(\\d+)/(\\d+).*val_loss:([0-9.]+).*train_time:(\\d+)ms\")\n",
    "rows = []\n",
    "for path in Path(LOG_DIR).glob('*.txt') if os.path.exists(LOG_DIR) else []:\n",
    "    run_id = path.stem\n",
    "    cfg = stage[stage['run_id']==run_id]\n",
    "    if cfg.empty:\n",
    "        continue\n",
    "    cfg = cfg.iloc[0]\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            m = VAL_RE.search(line)\n",
    "            if m:\n",
    "                step = int(m.group(1))\n",
    "                loss = float(m.group(3))\n",
    "                t_ms = int(m.group(4))\n",
    "                rows.append({'run_id': run_id, 'step': step, 'val_loss': loss, 'train_time_ms': t_ms, 'attn_gate': cfg['attn_gate'], 'learning_rate': cfg['learning_rate']})\n",
    "curves = pd.DataFrame(rows)\n",
    "if not curves.empty:\n",
    "    fig, axes = plt.subplots(1, len(curves['attn_gate'].unique()), figsize=(12,4), sharey=True)\n",
    "    if len(curves['attn_gate'].unique())==1:\n",
    "        axes=[axes]\n",
    "    for ax, (gate, sub) in zip(axes, curves.groupby('attn_gate')):\n",
    "        for lr, sublr in sub.groupby('learning_rate'):\n",
    "            sublr = sublr.sort_values('train_time_ms')\n",
    "            ax.plot(sublr['train_time_ms']/1000.0, sublr['val_loss'], label=f\"lr={lr:.5f}\")\n",
    "        ax.set_title(f\"attn_gate={gate}\")\n",
    "        ax.set_xlabel('train_time (s)')\n",
    "        ax.set_ylabel('val_loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No matching logs parsed; run jobs first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export curves\n",
    "if 'curves' in locals() and not curves.empty:\n",
    "    export_path = Path(PROJ_ROOT) / 'experiments' / 'log_curves_stage2_5.csv'\n",
    "    export_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    curves.to_csv(export_path, index=False)\n",
    "    print(f'Saved curves to {export_path}')\n",
    "else:\n",
    "    print('curves is empty; nothing to export.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
